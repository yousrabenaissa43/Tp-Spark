networks:
  enit_lab2_hive_hadoop_net:
    external: true   # use existing Hadoop network

services:
  spark-master:
    image: bde2020/spark-master:3.1.1-hadoop3.2
    container_name: spark-master
    ports:
      - "8079:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
      - HADOOP_CONF_DIR=hdfs://namenode:9000
    networks:
      - enit_lab2_hive_hadoop_net

  spark-worker-1:
    image: bde2020/spark-worker:3.1.1-hadoop3.2
    container_name: spark-worker-1
    ports:
      - "8081:8081"
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    networks:
      - enit_lab2_hive_hadoop_net

  spark-worker-2:
    image: bde2020/spark-worker:3.1.1-hadoop3.2
    container_name: spark-worker-2
    ports:
      - "8082:8081"
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    networks:
      - enit_lab2_hive_hadoop_net
